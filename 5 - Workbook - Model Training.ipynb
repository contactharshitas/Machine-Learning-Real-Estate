{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPANION WORKBOOK\n",
    "\n",
    "# Model Training\n",
    "\n",
    "To make the most out of this program, we strongly recommend you to:\n",
    "1. First practice writing and implementing all of the code from Coding Section of the online module.\n",
    "2. Then, freely experiment with and explore any interesting or confusing concepts. Simply insert new code cells and then use the help of Google and official documentation.\n",
    "3. Finally, tackle all of the exercises at the end. They will help you tie everything together and **learn in context.**\n",
    "\n",
    "#### <span style=\"color:#555\">MODULE CODE SANDBOX</span>\n",
    "\n",
    "Use this space to practice writing and implementing all of the code from Coding Section of the online module. Insert new code cells as needed, and feel free to write notes to yourself in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 5 algorithms\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1863, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('analytical_base_table.csv')\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting x and y\n",
    "y = df.tx_price\n",
    "x = df.drop('tx_price', axis =1)\n",
    "\n",
    "#Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=1234, test_size = 0.2)\n",
    "\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocessing & Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Others</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.902281e-16</td>\n",
       "      <td>-4.254613e-17</td>\n",
       "      <td>7.663519e-17</td>\n",
       "      <td>3.911860e-17</td>\n",
       "      <td>9.746119e-17</td>\n",
       "      <td>1.409760e-16</td>\n",
       "      <td>1.621373e-16</td>\n",
       "      <td>2.827995e-16</td>\n",
       "      <td>8.946050e-18</td>\n",
       "      <td>2.315448e-17</td>\n",
       "      <td>-2.132895e-16</td>\n",
       "      <td>1.022299e-16</td>\n",
       "      <td>2.151243e-16</td>\n",
       "      <td>-3.534831e-16</td>\n",
       "      <td>-1.768906e-16</td>\n",
       "      <td>-5.603273e-17</td>\n",
       "      <td>8.032352e-17</td>\n",
       "      <td>-1.070732e-16</td>\n",
       "      <td>1.852359e-16</td>\n",
       "      <td>9.239440e-18</td>\n",
       "      <td>-1.969342e-16</td>\n",
       "      <td>-7.004092e-18</td>\n",
       "      <td>-3.012132e-17</td>\n",
       "      <td>-7.004092e-18</td>\n",
       "      <td>-2.877266e-16</td>\n",
       "      <td>1.457447e-16</td>\n",
       "      <td>1.207088e-17</td>\n",
       "      <td>4.798548e-17</td>\n",
       "      <td>1.039437e-16</td>\n",
       "      <td>2.615358e-17</td>\n",
       "      <td>1.184362e-16</td>\n",
       "      <td>1.359092e-16</td>\n",
       "      <td>-2.747988e-16</td>\n",
       "      <td>-8.278240e-17</td>\n",
       "      <td>-2.752459e-16</td>\n",
       "      <td>2.772577e-16</td>\n",
       "      <td>-2.613867e-16</td>\n",
       "      <td>7.708226e-17</td>\n",
       "      <td>8.941393e-17</td>\n",
       "      <td>-8.941393e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.268801e+00</td>\n",
       "      <td>-1.697190e+00</td>\n",
       "      <td>-1.405276e+00</td>\n",
       "      <td>-3.662250e-01</td>\n",
       "      <td>-2.688343e+00</td>\n",
       "      <td>-8.405927e-01</td>\n",
       "      <td>-9.756023e-01</td>\n",
       "      <td>-5.928336e-01</td>\n",
       "      <td>-6.967768e-01</td>\n",
       "      <td>-7.559221e-01</td>\n",
       "      <td>-7.162235e-01</td>\n",
       "      <td>-8.905685e-01</td>\n",
       "      <td>-8.761722e-01</td>\n",
       "      <td>-2.495566e+00</td>\n",
       "      <td>-2.943413e+00</td>\n",
       "      <td>-3.511049e+00</td>\n",
       "      <td>-1.655736e+00</td>\n",
       "      <td>-1.532774e+00</td>\n",
       "      <td>-2.789591e+00</td>\n",
       "      <td>-3.439819e+00</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-1.147796e+00</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-2.315581e+00</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>-1.343434e+00</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-8.497402e-01</td>\n",
       "      <td>-1.176040e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.047185e-01</td>\n",
       "      <td>-6.224713e-01</td>\n",
       "      <td>-7.491974e-01</td>\n",
       "      <td>-3.219217e-01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>-7.128947e-01</td>\n",
       "      <td>-7.532980e-01</td>\n",
       "      <td>-5.928336e-01</td>\n",
       "      <td>-6.967768e-01</td>\n",
       "      <td>-6.412758e-01</td>\n",
       "      <td>-7.162235e-01</td>\n",
       "      <td>-7.350745e-01</td>\n",
       "      <td>-6.539411e-01</td>\n",
       "      <td>-8.327346e-01</td>\n",
       "      <td>-5.271130e-01</td>\n",
       "      <td>-6.881804e-01</td>\n",
       "      <td>-6.304329e-01</td>\n",
       "      <td>-6.378058e-01</td>\n",
       "      <td>-7.645042e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-8.648971e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-9.206779e-01</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>-1.343434e+00</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-8.497402e-01</td>\n",
       "      <td>-1.176040e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.273226e-01</td>\n",
       "      <td>4.522474e-01</td>\n",
       "      <td>-3.155383e-01</td>\n",
       "      <td>-1.885809e-01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>-3.936498e-01</td>\n",
       "      <td>-3.086896e-01</td>\n",
       "      <td>-3.559228e-01</td>\n",
       "      <td>-2.936977e-01</td>\n",
       "      <td>-3.737676e-01</td>\n",
       "      <td>-2.901213e-01</td>\n",
       "      <td>-3.074659e-01</td>\n",
       "      <td>-3.205944e-01</td>\n",
       "      <td>-7.690215e-02</td>\n",
       "      <td>2.279809e-01</td>\n",
       "      <td>5.775901e-02</td>\n",
       "      <td>-1.683864e-01</td>\n",
       "      <td>-2.043054e-01</td>\n",
       "      <td>2.480391e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-2.048007e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>9.257749e-03</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-8.497402e-01</td>\n",
       "      <td>8.497402e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.273226e-01</td>\n",
       "      <td>4.522474e-01</td>\n",
       "      <td>5.334699e-01</td>\n",
       "      <td>-2.831904e-02</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>3.512552e-01</td>\n",
       "      <td>5.805274e-01</td>\n",
       "      <td>1.178989e-01</td>\n",
       "      <td>1.093814e-01</td>\n",
       "      <td>1.994641e-01</td>\n",
       "      <td>3.490321e-01</td>\n",
       "      <td>4.700041e-01</td>\n",
       "      <td>2.905410e-01</td>\n",
       "      <td>6.789303e-01</td>\n",
       "      <td>7.313768e-01</td>\n",
       "      <td>7.598196e-01</td>\n",
       "      <td>4.740784e-01</td>\n",
       "      <td>4.109853e-01</td>\n",
       "      <td>7.543108e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>6.438946e-01</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>9.391934e-01</td>\n",
       "      <td>1.333663e+00</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>1.650203e+00</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>1.176040e+00</td>\n",
       "      <td>8.497402e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459364e+00</td>\n",
       "      <td>3.676403e+00</td>\n",
       "      <td>4.255036e+00</td>\n",
       "      <td>1.217405e+01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>4.820685e+00</td>\n",
       "      <td>4.359699e+00</td>\n",
       "      <td>5.685304e+00</td>\n",
       "      <td>5.618130e+00</td>\n",
       "      <td>5.740705e+00</td>\n",
       "      <td>6.740566e+00</td>\n",
       "      <td>5.990042e+00</td>\n",
       "      <td>4.346258e+00</td>\n",
       "      <td>4.609259e+00</td>\n",
       "      <td>1.536810e+00</td>\n",
       "      <td>2.046931e+00</td>\n",
       "      <td>1.779422e+01</td>\n",
       "      <td>1.726156e+01</td>\n",
       "      <td>1.766854e+00</td>\n",
       "      <td>2.360253e+00</td>\n",
       "      <td>3.128982e+00</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>4.227275e+00</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>1.869129e+00</td>\n",
       "      <td>1.333663e+00</td>\n",
       "      <td>6.353092e+00</td>\n",
       "      <td>3.990129e+00</td>\n",
       "      <td>3.767565e+00</td>\n",
       "      <td>2.714008e+00</td>\n",
       "      <td>5.058652e+00</td>\n",
       "      <td>1.650203e+00</td>\n",
       "      <td>3.767565e+00</td>\n",
       "      <td>3.558261e+00</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>2.069013e+00</td>\n",
       "      <td>3.942729e+00</td>\n",
       "      <td>5.364762e+00</td>\n",
       "      <td>1.176040e+00</td>\n",
       "      <td>8.497402e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               beds         baths          sqft      lot_size      basement  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean  -1.902281e-16 -4.254613e-17  7.663519e-17  3.911860e-17  9.746119e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.268801e+00 -1.697190e+00 -1.405276e+00 -3.662250e-01 -2.688343e+00   \n",
       "25%   -4.047185e-01 -6.224713e-01 -7.491974e-01 -3.219217e-01  3.717266e-01   \n",
       "50%    5.273226e-01  4.522474e-01 -3.155383e-01 -1.885809e-01  3.717266e-01   \n",
       "75%    5.273226e-01  4.522474e-01  5.334699e-01 -2.831904e-02  3.717266e-01   \n",
       "max    1.459364e+00  3.676403e+00  4.255036e+00  1.217405e+01  3.717266e-01   \n",
       "\n",
       "        restaurants     groceries     nightlife         cafes      shopping  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean   1.409760e-16  1.621373e-16  2.827995e-16  8.946050e-18  2.315448e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -8.405927e-01 -9.756023e-01 -5.928336e-01 -6.967768e-01 -7.559221e-01   \n",
       "25%   -7.128947e-01 -7.532980e-01 -5.928336e-01 -6.967768e-01 -6.412758e-01   \n",
       "50%   -3.936498e-01 -3.086896e-01 -3.559228e-01 -2.936977e-01 -3.737676e-01   \n",
       "75%    3.512552e-01  5.805274e-01  1.178989e-01  1.093814e-01  1.994641e-01   \n",
       "max    4.820685e+00  4.359699e+00  5.685304e+00  5.618130e+00  5.740705e+00   \n",
       "\n",
       "       arts_entertainment   beauty_spas   active_life    median_age  \\\n",
       "count        1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean        -2.132895e-16  1.022299e-16  2.151243e-16 -3.534831e-16   \n",
       "std          1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min         -7.162235e-01 -8.905685e-01 -8.761722e-01 -2.495566e+00   \n",
       "25%         -7.162235e-01 -7.350745e-01 -6.539411e-01 -8.327346e-01   \n",
       "50%         -2.901213e-01 -3.074659e-01 -3.205944e-01 -7.690215e-02   \n",
       "75%          3.490321e-01  4.700041e-01  2.905410e-01  6.789303e-01   \n",
       "max          6.740566e+00  5.990042e+00  4.346258e+00  4.609259e+00   \n",
       "\n",
       "            married  college_grad  property_tax     insurance  median_school  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   1.490000e+03   \n",
       "mean  -1.768906e-16 -5.603273e-17  8.032352e-17 -1.070732e-16   1.852359e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00   \n",
       "min   -2.943413e+00 -3.511049e+00 -1.655736e+00 -1.532774e+00  -2.789591e+00   \n",
       "25%   -5.271130e-01 -6.881804e-01 -6.304329e-01 -6.378058e-01  -7.645042e-01   \n",
       "50%    2.279809e-01  5.775901e-02 -1.683864e-01 -2.043054e-01   2.480391e-01   \n",
       "75%    7.313768e-01  7.598196e-01  4.740784e-01  4.109853e-01   7.543108e-01   \n",
       "max    1.536810e+00  2.046931e+00  1.779422e+01  1.726156e+01   1.766854e+00   \n",
       "\n",
       "        num_schools   two_and_two     recession  property_age  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean   9.239440e-18 -1.969342e-16 -7.004092e-18 -3.012132e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.439819e+00 -3.193783e-01 -6.014412e-01 -1.147796e+00   \n",
       "25%    4.268957e-01 -3.193783e-01 -6.014412e-01 -8.648971e-01   \n",
       "50%    4.268957e-01 -3.193783e-01 -6.014412e-01 -2.048007e-01   \n",
       "75%    4.268957e-01 -3.193783e-01  1.661557e+00  6.438946e-01   \n",
       "max    2.360253e+00  3.128982e+00  1.661557e+00  4.227275e+00   \n",
       "\n",
       "       during_recession  school_score  exterior_walls_Brick  \\\n",
       "count      1.490000e+03  1.490000e+03          1.490000e+03   \n",
       "mean      -7.004092e-18 -2.877266e-16          1.457447e-16   \n",
       "std        1.000000e+00  1.000000e+00          1.000000e+00   \n",
       "min       -6.014412e-01 -2.315581e+00         -7.493115e-01   \n",
       "25%       -6.014412e-01 -9.206779e-01         -7.493115e-01   \n",
       "50%       -6.014412e-01  9.257749e-03         -7.493115e-01   \n",
       "75%        1.661557e+00  9.391934e-01          1.333663e+00   \n",
       "max        1.661557e+00  1.869129e+00          1.333663e+00   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                 1.490000e+03                1.490000e+03   \n",
       "mean                  1.207088e-17                4.798548e-17   \n",
       "std                   1.000000e+00                1.000000e+00   \n",
       "min                  -1.572980e-01               -2.504503e-01   \n",
       "25%                  -1.572980e-01               -2.504503e-01   \n",
       "50%                  -1.572980e-01               -2.504503e-01   \n",
       "75%                  -1.572980e-01               -2.504503e-01   \n",
       "max                   6.353092e+00                3.990129e+00   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Others  \\\n",
       "count          1.490000e+03            1.490000e+03           1.490000e+03   \n",
       "mean           1.039437e-16            2.615358e-17           1.184362e-16   \n",
       "std            1.000000e+00            1.000000e+00           1.000000e+00   \n",
       "min           -2.652453e-01           -3.682115e-01          -1.975485e-01   \n",
       "25%           -2.652453e-01           -3.682115e-01          -1.975485e-01   \n",
       "50%           -2.652453e-01           -3.682115e-01          -1.975485e-01   \n",
       "75%           -2.652453e-01           -3.682115e-01          -1.975485e-01   \n",
       "max            3.767565e+00            2.714008e+00           5.058652e+00   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                        1.490000e+03         1.490000e+03  1.490000e+03   \n",
       "mean                         1.359092e-16        -2.747988e-16 -8.278240e-17   \n",
       "std                          1.000000e+00         1.000000e+00  1.000000e+00   \n",
       "min                         -6.055792e-01        -2.652453e-01 -2.808475e-01   \n",
       "25%                         -6.055792e-01        -2.652453e-01 -2.808475e-01   \n",
       "50%                         -6.055792e-01        -2.652453e-01 -2.808475e-01   \n",
       "75%                          1.650203e+00        -2.652453e-01 -2.808475e-01   \n",
       "max                          1.650203e+00         3.767565e+00  3.558261e+00   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing    roof_Other  \\\n",
       "count              1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean              -2.752459e-16  2.772577e-16 -2.613867e-16   \n",
       "std                1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min               -1.343434e+00 -4.829980e-01 -2.534612e-01   \n",
       "25%               -1.343434e+00 -4.829980e-01 -2.534612e-01   \n",
       "50%                7.438617e-01 -4.829980e-01 -2.534612e-01   \n",
       "75%                7.438617e-01 -4.829980e-01 -2.534612e-01   \n",
       "max                7.438617e-01  2.069013e+00  3.942729e+00   \n",
       "\n",
       "       roof_Shake Shingle  property_type_Apartment / Condo / Townhouse  \\\n",
       "count        1.490000e+03                                 1.490000e+03   \n",
       "mean         7.708226e-17                                 8.941393e-17   \n",
       "std          1.000000e+00                                 1.000000e+00   \n",
       "min         -1.862765e-01                                -8.497402e-01   \n",
       "25%         -1.862765e-01                                -8.497402e-01   \n",
       "50%         -1.862765e-01                                -8.497402e-01   \n",
       "75%         -1.862765e-01                                 1.176040e+00   \n",
       "max          5.364762e+00                                 1.176040e+00   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                 1.490000e+03  \n",
       "mean                 -8.941393e-17  \n",
       "std                   1.000000e+00  \n",
       "min                  -1.176040e+00  \n",
       "25%                  -1.176040e+00  \n",
       "50%                   8.497402e-01  \n",
       "75%                   8.497402e-01  \n",
       "max                   8.497402e-01  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new = (x_train - x_train.mean())/x_train.std()\n",
    "x_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' %x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Others</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-3.511</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.255</td>\n",
       "      <td>12.174</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.685</td>\n",
       "      <td>5.618</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.990</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.609</td>\n",
       "      <td>1.537</td>\n",
       "      <td>2.047</td>\n",
       "      <td>17.794</td>\n",
       "      <td>17.262</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>1.662</td>\n",
       "      <td>4.227</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000  1490.000  1490.000     1490.000   1490.000   \n",
       "mean    -0.000   -0.000    0.000     0.000     0.000        0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.697   -1.405    -0.366    -2.688       -0.841     -0.976   \n",
       "25%     -0.405   -0.622   -0.749    -0.322     0.372       -0.713     -0.753   \n",
       "50%      0.527    0.452   -0.316    -0.189     0.372       -0.394     -0.309   \n",
       "75%      0.527    0.452    0.533    -0.028     0.372        0.351      0.581   \n",
       "max      1.459    3.676    4.255    12.174     0.372        4.821      4.360   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       0.000    0.000     0.000              -0.000        0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.593   -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.593   -0.697    -0.641              -0.716       -0.735   \n",
       "50%       -0.356   -0.294    -0.374              -0.290       -0.307   \n",
       "75%        0.118    0.109     0.199               0.349        0.470   \n",
       "max        5.685    5.618     5.741               6.741        5.990   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean         0.000      -0.000   -0.000        -0.000         0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.876      -2.496   -2.943        -3.511        -1.656   \n",
       "25%         -0.654      -0.833   -0.527        -0.688        -0.630   \n",
       "50%         -0.321      -0.077    0.228         0.058        -0.168   \n",
       "75%          0.291       0.679    0.731         0.760         0.474   \n",
       "max          4.346       4.609    1.537         2.047        17.794   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  recession  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000   1490.000   \n",
       "mean      -0.000          0.000        0.000       -0.000     -0.000   \n",
       "std        1.000          1.000        1.000        1.000      1.000   \n",
       "min       -1.533         -2.790       -3.440       -0.319     -0.601   \n",
       "25%       -0.638         -0.765        0.427       -0.319     -0.601   \n",
       "50%       -0.204          0.248        0.427       -0.319     -0.601   \n",
       "75%        0.411          0.754        0.427       -0.319      1.662   \n",
       "max       17.262          1.767        2.360        3.129      1.662   \n",
       "\n",
       "       property_age  during_recession  school_score  exterior_walls_Brick  \\\n",
       "count      1490.000          1490.000      1490.000              1490.000   \n",
       "mean         -0.000            -0.000        -0.000                 0.000   \n",
       "std           1.000             1.000         1.000                 1.000   \n",
       "min          -1.148            -0.601        -2.316                -0.749   \n",
       "25%          -0.865            -0.601        -0.921                -0.749   \n",
       "50%          -0.205            -0.601         0.009                -0.749   \n",
       "75%           0.644             1.662         0.939                 1.334   \n",
       "max           4.227             1.662         1.869                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.000                       0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Others  \\\n",
       "count              1490.000                1490.000               1490.000   \n",
       "mean                  0.000                   0.000                  0.000   \n",
       "std                   1.000                   1.000                  1.000   \n",
       "min                  -0.265                  -0.368                 -0.198   \n",
       "25%                  -0.265                  -0.368                 -0.198   \n",
       "50%                  -0.265                  -0.368                 -0.198   \n",
       "75%                  -0.265                  -0.368                 -0.198   \n",
       "max                   3.768                   2.714                  5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.000               -0.000        -0.000   \n",
       "std                                 1.000                1.000         1.000   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1490.000      1490.000    1490.000            1490.000   \n",
       "mean                     -0.000         0.000      -0.000               0.000   \n",
       "std                       1.000         1.000       1.000               1.000   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.000   \n",
       "std                                          1.000   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                        -0.000  \n",
       "std                          1.000  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Others</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.308</td>\n",
       "      <td>2.504</td>\n",
       "      <td>2204.855</td>\n",
       "      <td>11624.788</td>\n",
       "      <td>0.882</td>\n",
       "      <td>43.775</td>\n",
       "      <td>5.024</td>\n",
       "      <td>5.485</td>\n",
       "      <td>6.000</td>\n",
       "      <td>46.477</td>\n",
       "      <td>3.587</td>\n",
       "      <td>25.681</td>\n",
       "      <td>16.399</td>\n",
       "      <td>38.987</td>\n",
       "      <td>67.472</td>\n",
       "      <td>65.185</td>\n",
       "      <td>449.802</td>\n",
       "      <td>135.646</td>\n",
       "      <td>6.438</td>\n",
       "      <td>2.842</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.255</td>\n",
       "      <td>24.611</td>\n",
       "      <td>0.255</td>\n",
       "      <td>18.153</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.029</td>\n",
       "      <td>0.921</td>\n",
       "      <td>1299.192</td>\n",
       "      <td>35999.826</td>\n",
       "      <td>0.323</td>\n",
       "      <td>47.154</td>\n",
       "      <td>4.483</td>\n",
       "      <td>8.732</td>\n",
       "      <td>8.021</td>\n",
       "      <td>58.668</td>\n",
       "      <td>4.755</td>\n",
       "      <td>26.201</td>\n",
       "      <td>16.596</td>\n",
       "      <td>6.751</td>\n",
       "      <td>18.860</td>\n",
       "      <td>16.151</td>\n",
       "      <td>202.203</td>\n",
       "      <td>64.966</td>\n",
       "      <td>2.060</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.436</td>\n",
       "      <td>20.624</td>\n",
       "      <td>0.436</td>\n",
       "      <td>6.525</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>687.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>147.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1280.000</td>\n",
       "      <td>1441.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>316.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1821.000</td>\n",
       "      <td>3484.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>409.000</td>\n",
       "      <td>122.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2720.000</td>\n",
       "      <td>10558.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>525.000</td>\n",
       "      <td>159.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7677.000</td>\n",
       "      <td>435600.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>340.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>175.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>1553.000</td>\n",
       "      <td>524.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths     sqft   lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000  373.000    373.000   373.000      373.000    373.000   \n",
       "mean    3.308   2.504 2204.855  11624.788     0.882       43.775      5.024   \n",
       "std     1.029   0.921 1299.192  35999.826     0.323       47.154      4.483   \n",
       "min     1.000   1.000  687.000      0.000     0.000        0.000      0.000   \n",
       "25%     3.000   2.000 1280.000   1441.000     1.000       10.000      1.000   \n",
       "50%     3.000   2.000 1821.000   3484.000     1.000       26.000      4.000   \n",
       "75%     4.000   3.000 2720.000  10558.000     1.000       63.000      7.000   \n",
       "max     5.000   6.000 7677.000 435600.000     1.000      266.000     22.000   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       5.485   6.000    46.477               3.587       25.681   \n",
       "std        8.732   8.021    58.668               4.755       26.201   \n",
       "min        0.000   0.000     0.000               0.000        0.000   \n",
       "25%        1.000   1.000    10.000               0.000        6.000   \n",
       "50%        2.000   3.000    26.000               2.000       17.000   \n",
       "75%        6.000   7.000    57.000               5.000       38.000   \n",
       "max       54.000  45.000   340.000              35.000      175.000   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean        16.399      38.987   67.472        65.185       449.802   \n",
       "std         16.596       6.751   18.860        16.151       202.203   \n",
       "min          0.000      27.000   13.000        19.000       147.000   \n",
       "25%          6.000      34.000   56.000        53.000       316.000   \n",
       "50%         11.000      38.000   71.000        66.000       409.000   \n",
       "75%         22.000      43.000   82.000        78.000       525.000   \n",
       "max         88.000      66.000  100.000        99.000      1553.000   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  recession  \\\n",
       "count    373.000        373.000      373.000      373.000    373.000   \n",
       "mean     135.646          6.438        2.842        0.107      0.255   \n",
       "std       64.966          2.060        0.463        0.310      0.436   \n",
       "min       47.000          1.000        1.000        0.000      0.000   \n",
       "25%       92.000          5.000        3.000        0.000      0.000   \n",
       "50%      122.000          7.000        3.000        0.000      0.000   \n",
       "75%      159.000          8.000        3.000        0.000      1.000   \n",
       "max      524.000         10.000        4.000        1.000      1.000   \n",
       "\n",
       "       property_age  during_recession  school_score  exterior_walls_Brick  \\\n",
       "count       373.000           373.000       373.000               373.000   \n",
       "mean         24.611             0.255        18.153                 0.391   \n",
       "std          20.624             0.436         6.525                 0.489   \n",
       "min           0.000             0.000         3.000                 0.000   \n",
       "25%           5.000             0.000        12.000                 0.000   \n",
       "50%          21.000             0.000        18.000                 0.000   \n",
       "75%          39.000             1.000        24.000                 1.000   \n",
       "max          94.000             1.000        30.000                 1.000   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.032                       0.048   \n",
       "std                          0.177                       0.215   \n",
       "min                          0.000                       0.000   \n",
       "25%                          0.000                       0.000   \n",
       "50%                          0.000                       0.000   \n",
       "75%                          0.000                       0.000   \n",
       "max                          1.000                       1.000   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Others  \\\n",
       "count               373.000                 373.000                373.000   \n",
       "mean                  0.059                   0.118                  0.029   \n",
       "std                   0.236                   0.323                  0.169   \n",
       "min                   0.000                   0.000                  0.000   \n",
       "25%                   0.000                   0.000                  0.000   \n",
       "50%                   0.000                   0.000                  0.000   \n",
       "75%                   0.000                   0.000                  0.000   \n",
       "max                   1.000                   1.000                  1.000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                             373.000              373.000       373.000   \n",
       "mean                                0.257                0.064         0.072   \n",
       "std                                 0.438                0.246         0.259   \n",
       "min                                 0.000                0.000         0.000   \n",
       "25%                                 0.000                0.000         0.000   \n",
       "50%                                 0.000                0.000         0.000   \n",
       "75%                                 1.000                0.000         0.000   \n",
       "max                                 1.000                1.000         1.000   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                   373.000       373.000     373.000             373.000   \n",
       "mean                      0.649         0.188       0.067               0.024   \n",
       "std                       0.478         0.391       0.250               0.154   \n",
       "min                       0.000         0.000       0.000               0.000   \n",
       "25%                       0.000         0.000       0.000               0.000   \n",
       "50%                       1.000         0.000       0.000               0.000   \n",
       "75%                       1.000         0.000       0.000               0.000   \n",
       "max                       1.000         1.000       1.000               1.000   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.475   \n",
       "std                                          0.500   \n",
       "min                                          0.000   \n",
       "25%                                          0.000   \n",
       "50%                                          0.000   \n",
       "75%                                          1.000   \n",
       "max                                          1.000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                      373.000  \n",
       "mean                         0.525  \n",
       "std                          0.500  \n",
       "min                          0.000  \n",
       "25%                          0.000  \n",
       "50%                          1.000  \n",
       "75%                          1.000  \n",
       "max                          1.000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Others</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-1.740</td>\n",
       "      <td>-2.843</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.128</td>\n",
       "      <td>12.149</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>3.915</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.349</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.912</td>\n",
       "      <td>4.013</td>\n",
       "      <td>4.156</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.988</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>1.662</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths    sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000 373.000   373.000   373.000      373.000    373.000   \n",
       "mean   -0.117  -0.081  -0.091    -0.032     0.011        0.091      0.141   \n",
       "std     0.959   0.989   1.002     1.034     0.988        1.004      0.996   \n",
       "min    -2.269  -1.697  -1.261    -0.366    -2.688       -0.841     -0.976   \n",
       "25%    -0.405  -0.622  -0.804    -0.325     0.372       -0.628     -0.753   \n",
       "50%    -0.405  -0.622  -0.387    -0.266     0.372       -0.287     -0.086   \n",
       "75%     0.527   0.452   0.306    -0.063     0.372        0.500      0.581   \n",
       "max     1.459   3.676   4.128    12.149     0.372        4.821      3.915   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       0.057   0.109     0.132               0.048        0.108   \n",
       "std        1.034   1.078     1.121               1.013        1.019   \n",
       "min       -0.593  -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.474  -0.562    -0.565              -0.716       -0.657   \n",
       "50%       -0.356  -0.294    -0.259              -0.290       -0.230   \n",
       "75%        0.118   0.244     0.333               0.349        0.587   \n",
       "max        5.804   5.349     5.741               6.741        5.912   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean         0.035       0.072   -0.101         0.010        -0.064   \n",
       "std          0.922       1.021    0.949         0.945         0.890   \n",
       "min         -0.876      -1.740   -2.843        -2.692        -1.396   \n",
       "25%         -0.543      -0.682   -0.678        -0.703        -0.652   \n",
       "50%         -0.265      -0.077    0.077         0.058        -0.243   \n",
       "75%          0.346       0.679    0.631         0.760         0.267   \n",
       "max          4.013       4.156    1.537         1.988         4.791   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  recession  \\\n",
       "count    373.000        373.000      373.000      373.000    373.000   \n",
       "mean      -0.055         -0.036        0.121        0.050     -0.025   \n",
       "std        0.908          1.043        0.895        1.068      0.987   \n",
       "min       -1.295         -2.790       -3.440       -0.319     -0.601   \n",
       "25%       -0.666         -0.765        0.427       -0.319     -0.601   \n",
       "50%       -0.246          0.248        0.427       -0.319     -0.601   \n",
       "75%        0.271          0.754        0.427       -0.319      1.662   \n",
       "max        5.375          1.767        2.360        3.129      1.662   \n",
       "\n",
       "       property_age  during_recession  school_score  exterior_walls_Brick  \\\n",
       "count       373.000           373.000       373.000               373.000   \n",
       "mean          0.013            -0.025         0.033                 0.066   \n",
       "std           0.972             0.987         1.011                 1.018   \n",
       "min          -1.148            -0.601        -2.316                -0.749   \n",
       "25%          -0.912            -0.601        -0.921                -0.749   \n",
       "50%          -0.158            -0.601         0.009                -0.749   \n",
       "75%           0.691             1.662         0.939                 1.334   \n",
       "max           3.284             1.662         1.869                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.052                      -0.046   \n",
       "std                          1.150                       0.910   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Others  \\\n",
       "count               373.000                 373.000                373.000   \n",
       "mean                 -0.027                  -0.005                 -0.043   \n",
       "std                   0.951                   0.996                  0.890   \n",
       "min                  -0.265                  -0.368                 -0.198   \n",
       "25%                  -0.265                  -0.368                 -0.198   \n",
       "50%                  -0.265                  -0.368                 -0.198   \n",
       "75%                  -0.265                  -0.368                 -0.198   \n",
       "max                   3.768                   2.714                  5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                             373.000              373.000       373.000   \n",
       "mean                               -0.025               -0.006        -0.003   \n",
       "std                                 0.988                0.991         0.996   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                   373.000       373.000     373.000             373.000   \n",
       "mean                      0.011        -0.004       0.028              -0.052   \n",
       "std                       0.998         0.998       1.051               0.853   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.112   \n",
       "std                                          1.013   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                      373.000  \n",
       "mean                        -0.112  \n",
       "std                          1.013  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new = (x_test - x_train.mean()) / x_train.std()\n",
    "x_test_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For Standardisation\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines dictionary\n",
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=123))\n",
    "}\n",
    "# Add a pipeline for Elastic-Net\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=123))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=123,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False))],\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=123,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'lasso__alpha': 1.0,\n",
       " 'lasso__copy_X': True,\n",
       " 'lasso__fit_intercept': True,\n",
       " 'lasso__max_iter': 1000,\n",
       " 'lasso__normalize': False,\n",
       " 'lasso__positive': False,\n",
       " 'lasso__precompute': False,\n",
       " 'lasso__random_state': 123,\n",
       " 'lasso__selection': 'cyclic',\n",
       " 'lasso__tol': 0.0001,\n",
       " 'lasso__warm_start': False}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['lasso'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_hyperparameter = {\n",
    "    'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] }\n",
    "\n",
    "ridge_hyperparameter = {\n",
    "    'ridge_alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_hyperparameter = {\n",
    "    'enet_alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] ,\n",
    "    'enet_l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lasso' : lasso_hyperparameter,\n",
    "    'ridge' : ridge_hyperparameter,\n",
    "    'enet'  : enet_hyperparameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(pipeline['lasso'], hyperparameters['lasso'], cv = 10, n_jobs=-1)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore ConvergenceWarning messages\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter ridge_alpha for estimator Pipeline(memory=None,\n     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=123, solver='auto', tol=0.001))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 514, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 147, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 215, in set_params\n    (key, self))\nValueError: Invalid parameter ridge_alpha for estimator Pipeline(memory=None,\n     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=123, solver='auto', tol=0.001))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-dfcbdf20335d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Fit model on X_train, y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Store model in fitted_models[name]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter ridge_alpha for estimator Pipeline(memory=None,\n     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=123, solver='auto', tol=0.001))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#555\">EXERCISES</span>\n",
    "\n",
    "Complete each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.1 - Coding Section Checkpoint</span>\n",
    "\n",
    "Before moving on, it's imperative that you've been following along the online Coding Section of this module. Those are core to each module and often contain **mission-critical code**, which means that the following modules REQUIRE you to have run that code.\n",
    "\n",
    "#### A.) First, confirm that you've successfully separated the data into a training set and a test set.\n",
    "* How many observations are in the training set?\n",
    "* How many observations are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, display the Ridge regression pipeline object saved in the pipelines dictionary.\n",
    "* What steps are in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=123, solver='auto', tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "print(pipelines['ridge'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=123, solver='auto', tol=0.001))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, display the <code>l1_ratio</code> hyperparameter values to try for your Elastic-Net algorithm.\n",
    "* **Tip:** Remember the naming convention within pipelines (need the named step first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.3, 0.5, 0.7, 0.9]\n"
     ]
    }
   ],
   "source": [
    "print(enet_hyperparameter['enet_l1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.2 - Sklearn's Standard Scaler</span>\n",
    "\n",
    "Whenever you preprocess your dataset, it's important to use the same **preprocessing parameters** on new data as you used on the training set. So if you standardize your dataset, you must also standardize the test set with the same means and standard deviations from the training set.\n",
    "\n",
    "#### A.) First, display the standardization parameters for the <code>beds</code> feature in the training set (<code>X_train</code>).\n",
    "* You'll need the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1490.000\n",
       "mean       3.434\n",
       "std        1.073\n",
       "min        1.000\n",
       "25%        3.000\n",
       "50%        4.000\n",
       "75%        4.000\n",
       "max        5.000\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['beds'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0729140858452646\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TRAINING set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689    1.459\n",
       "1531    0.527\n",
       "668    -0.405\n",
       "1740    1.459\n",
       "117    -1.337\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train['beds'].head() - X_train['beds'].mean() ) / X_train['beds'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "1689    1.459\n",
    "1531    0.527\n",
    "668    -0.405\n",
    "1740    1.459\n",
    "117    -1.337\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TEST set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266   -1.337\n",
       "790   -0.405\n",
       "222   -1.337\n",
       "220   -1.337\n",
       "920   -0.405\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test['beds'].head() - X_train['beds'].mean() ) / X_train['beds'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "266   -1.337\n",
    "790   -0.405\n",
    "222   -1.337\n",
    "220   -1.337\n",
    "920   -0.405\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Scikit-Learn's <code>StandardScaler()</code> class allows you to save those preprocessing parameters learned from the training set.\n",
    "1. First, initialize and instance of the scaler class.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "scaler = StandardScaler()\n",
    "</pre>\n",
    "\n",
    "2. Then, call the <code>.fit()</code> while passing in the **entire** training set (all of the features, not just beds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hs/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.) Now you can display the preprocessing parameters directly from the <code>scaler</code> object.\n",
    "* It will save the means from all features as an array in <code>.mean_</code>.\n",
    "* It will save the standard deviations from all features as an array in <code>.scale_</code>.\n",
    "* **Tip:** The <code>beds</code> feature should be the first one.\n",
    "* Check for yourself that the preprocessing parameters are the same as the ones you found in part (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.434228187919463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0725539871320342"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(scaler.mean_[0])\n",
    "scaler.scale_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0725539871320342\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.) Next, use the <code>scaler</code> object to <code>.transform()</code> your test set and save it as <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hs/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test_new = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you use <code>scaler</code> to transform a dataset, it returns a NumPy array and NOT a Pandas DataFrame.\n",
    "\n",
    "#### G.) Confirm this for yourself. Display the class and shape of <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 40)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_new)\n",
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'numpy.ndarray'&gt;\n",
    "(373, 39)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.) Finally, display the first 5 transformed values for the <code>beds</code> feature.\n",
    "* Because <code>X_test_new</code> is a NumPy array, you won't be able to just call <code>.beds</code> like with Pandas DataFrames. If you try that, you'll get the error:\n",
    "\n",
    "<pre>\n",
    "<span style=\"color:crimson\">AttributeError:</span> 'numpy.ndarray' object has no attribute 'beds'\n",
    "</pre>\n",
    "\n",
    "* Instead, you'll need to index the NumPy array to get the **first 5 rows** from the **first column**. (This is just meant as a refresher and a bit of practice.)\n",
    "* Confirm that the values are the same as the ones you found in part (C) manually. Note that the rounding/precision may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33720839, -0.40485439, -1.33720839, -1.33720839, -0.40485439])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new[:5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.3 - Tree Pipelines</span>\n",
    "\n",
    "In the Coding Section, we created a pipeline dictionary with model pipelines for Lasso, Ridge, and Elastic-Net regressions. In this exercise, let's add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['rf'] = make_pipeline(StandardScaler(),RandomForestRegressor(random_state=123))\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(),GradientBoostingRegressor(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Just as a quick sanity check, display the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "  ...rs='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['rf'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) As another quick sanity check, display the class for the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipelines['rf'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's check that all of the model pipelines are of the correct type. For each item in your <code>pipelines</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for key,value in pipelines.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "ridge &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "enet &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "rf &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "gb &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.4 - Hyperparameter Grids</span>\n",
    "\n",
    "In the Coding Section, we declared hyperparameter grids for our regularized regression algorithms: Lasso, Ridge, and Elastic-Net. Next, let's do the same for our tree ensembles.\n",
    "\n",
    "\n",
    "#### Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "The first one we'll tune is <code style=\"color:steelblue; font-weight:bold\">n_estimators</code>.\n",
    "* This is the number of decision trees to include in the random forest.\n",
    "* Usually, more is better.\n",
    "* The default value is 10, which is usually too few.\n",
    "* Let's try 100 and 200.\n",
    "\n",
    "The second one we'll tune is <code style=\"color:steelblue; font-weight:bold\">max_features</code>.\n",
    "* This controls the number of features each tree is allowed to choose from.\n",
    "* It's what allows your random forest to perform feature selection.\n",
    "* The default value is <code style=\"color:crimson\">'auto'</code>, which sets <code style=\"color:steelblue\">max_features = n_features</code>.\n",
    "* Let's also try <code style=\"color:crimson\">'sqrt'</code>, which sets <code style=\"color:steelblue\">max_features = sqrt(n_features)</code>\n",
    "* And <code style=\"color:crimson\">0.33</code>, which sets <code style=\"color:steelblue\">max_features = 0.33 * n_features</code>\n",
    "\n",
    "#### A.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_hyperparameters = { 'randomforestregressor_nestimators' : [100,200],\n",
    "                     'randomforestregressor_maxfeatures' : ['auto','sqrt',0.33]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "#### B.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor_nestimators': [ 100,200],\n",
    "    'gradientboostingregressor_learningrate' : [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor_maxdepth' : [1,3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "#### C.) Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "     'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was not found in hyperparameters\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was not found in hyperparameters\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was not found in hyperparameters\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "enet was found in hyperparameters, and it is a grid.\n",
    "gb was found in hyperparameters, and it is a grid.\n",
    "ridge was found in hyperparameters, and it is a grid.\n",
    "rf was found in hyperparameters, and it is a grid.\n",
    "lasso was found in hyperparameters, and it is a grid.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.5 - Model Dictionaries</span>\n",
    "\n",
    "Similar to how we created dictionaries for our pipelines and hyperparameter grids, we can do the same for our fitted models. Obviously, there are other valid ways to organize your code and models, but this is a simple and practical way that does the job. By the end of the script, you'll have various dictionary objects that can each be accessed by the same consistent keys.\n",
    "\n",
    "#### A.) Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> to store models that have been tuned using cross-validation.\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lasso'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-d99d5602e481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Loop through model pipelines, tuning each one and saving it to fitted_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Fit model on X_train, y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lasso'"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Check that the models are of the correct type. For each item in your <code>fitted_models</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "ridge &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "enet &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "rf &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "gb &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, run this code to check that the models have been fitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso has been fitted.\n",
    "ridge has been fitted.\n",
    "enet has been fitted.\n",
    "rf has been fitted.\n",
    "gb has been fitted.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.6 - Model Selection</span>\n",
    "\n",
    "In the Coding Section, we displayed performance metrics for a sample Lasso regression model. Now, let's do the same thing for all of our models, including our tree ensembles and then pick the final winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) First, display the cross-validated training performance for each model in <code style=\"color:SteelBlue\">fitted_models</code> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso 0.30862751105084013\n",
    "ridge 0.3166111585985649\n",
    "enet 0.34285741369864786\n",
    "rf 0.4801823564169308\n",
    "gb 0.48778099198016756\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "\n",
    "<pre>\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.4088862476281637\n",
    "MAE: 85035.54256465772\n",
    "\n",
    "ridge\n",
    "--------\n",
    "R^2: 0.4093396476329718\n",
    "MAE: 84978.03564808934\n",
    "\n",
    "enet\n",
    "--------\n",
    "R^2: 0.4038573361696519\n",
    "MAE: 86529.0068234889\n",
    "\n",
    "rf\n",
    "--------\n",
    "R^2: 0.5712128842598444\n",
    "MAE: 67885.87587131368\n",
    "\n",
    "gb\n",
    "--------\n",
    "R^2: 0.5270040007880257\n",
    "MAE: 71245.11216404787\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, ask yourself these questions to pick the winning model:\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "* Which model had the lowest mean absolute error?\n",
    "* Are these two models the same one?\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "* Does it satisfy our project's win condition? (**Tip:** In the event of ambiguous results based on the previous questions, THIS should be your final deciding factor on whether a model is \"good enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, plot the performance of the winning model on the test set.\n",
    "* Plot a scatterplot with predicted transaction price on the x-axis and actual transaction price on the y-axis.\n",
    "* This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal (what does the 45 degree diagonal line represent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<img src=\"data:image/png;base64,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&#10;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.7 - Saving Your Model</span>\n",
    "\n",
    "Great job, you've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "#### A.) First, display the class of your winning \"model\" in the <code>fitted_models</code> dictionary object.\n",
    "* Remember, you can access it with its corresponding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.model_selection._search.GridSearchCV\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> class. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "#### B.) Confirm you can access the winning model pipeline. Display the class of the model pipeline.\n",
    "* **Tip:** You can use its <code style=\"color:steelblue\">best\\_estimator_</code> method to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.pipeline.Pipeline\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Display the winning pipeline object directly. What are the values of the winning values for our hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's save the winning <code style=\"color:steelblue\">Pipeline</code> object object. To do so, we'll import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk.\n",
    "* First, <code>import pickle</code>.\n",
    "* Then, use the following syntax to \"dump\" your model into a pickle file.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(<strong>insert answer to previous question here</strong>, f)\n",
    "</pre>\n",
    "* **Note:** We'll show you in the next project how to take this a step further and use the pickled model for various use cases. For now, we don't want to spread ourselves too thin over too many topics, so let's just save that final model and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
